# [ACTIVE] Epic 002: é¡¹ç›®è§„èŒƒå³æœåŠ¡ (Project Standards as MCP)

**Epic ID**: EPIC-002
**åˆ›å»ºæ—¥æœŸ**: 2025-10-27
**è´Ÿè´£äºº**: EvolvAI Team
**çŠ¶æ€**: [ACTIVE]
**ä¼˜å…ˆçº§**: [P1]
**ä¼°ç®—**: 10äººå¤© (2å‘¨ MVP)

---

## ğŸ“‹ Epicæ¦‚è¿°

### é—®é¢˜é™ˆè¿°

**å½“å‰å›°å¢ƒ**ï¼šAIåŠ©æ‰‹é¢‘ç¹è¿åé¡¹ç›®æ–‡æ¡£è§„èŒƒ
- ğŸ“„ æ–‡æ¡£éšæ„åˆ›å»ºåœ¨é”™è¯¯ä½ç½®ï¼ˆé¡¹ç›®æ ¹ç›®å½•ã€ä¸´æ—¶æ–‡ä»¶å¤¹ï¼‰
- ğŸ·ï¸ å‘½åä¸ä¸€è‡´ï¼ˆmy-notes.md, temp.md, éšæ„å‘½åï¼‰
- ğŸ“ ç»“æ„ç¼ºå¤±ï¼ˆç¼ºå°‘å¿…å¡«ç« èŠ‚ã€ä¸šåŠ¡ä»·å€¼è¯´æ˜ï¼‰
- ğŸ”„ åå¤è¿”å·¥ï¼ˆåˆ›å»ºâ†’çº æ­£â†’é‡å†™ï¼Œtokenæµªè´¹ä¸¥é‡ï¼‰

**æ ¹æœ¬åŸå› **ï¼š
```
é™æ€æ–‡æ¡£è§„èŒƒï¼ˆCLAUDE.md, .structure.mdï¼‰
    â†“
AIé˜…è¯»ä½†æ— å¼ºåˆ¶åŠ›
    â†“
ä¾èµ–"è‡ªè§‰éµå®ˆ"ï¼Œç»å¸¸å¤±è´¥
    â†“
éšå½¢tokenæµªè´¹å¤§æˆ·
```

### ä¸šåŠ¡ä»·å€¼

**æ ¸å¿ƒç†å¿µ**ï¼š**è§„èŒƒå³æœåŠ¡ > è§„èŒƒå³æ–‡æ¡£**

å°†é¡¹ç›®æœ€ä¼˜å®è·µä»"é™æ€æ–‡æ¡£"å‡çº§ä¸º"å¯æ‰§è¡Œçš„è¡Œä¸ºçº¦æŸæœåŠ¡"ï¼Œè®©AI**æƒ³è¿åä¹Ÿåšä¸åˆ°**ã€‚

**ç›´æ¥æ”¶ç›Š**ï¼š
- **å‡å°‘è¿”å·¥tokenæµªè´¹**ï¼šå°‘èµ°å¼¯è·¯ï¼Œå‡å°‘"é”™è¯¯åˆ›å»ºâ†’çº æ­£â†’é‡å†™"å¾ªç¯
- **æé«˜é¦–æ¬¡æˆåŠŸç‡**ï¼šé€šè¿‡åŸåˆ™é©±åŠ¨çš„æŒ‡å¯¼ï¼Œé¦–æ¬¡åˆ›å»ºå³ç¬¦åˆè§„èŒƒ
- **é™ä½TPST**ï¼šé¢„è®¡å‡å°‘æ–‡æ¡£ç›¸å…³tokenæ¶ˆè€—40%ï¼ˆç›®æ ‡ï¼‰
- **è·¨é¡¹ç›®å¤ç”¨**ï¼šæ ‡å‡†å¯ç»§æ‰¿ã€å¯ç»„åˆï¼Œé€‚ç”¨äºä»»ä½•é¡¹ç›®

**æˆ˜ç•¥ä»·å€¼**ï¼š
- ä¸Epic-001å½¢æˆ"è¡Œä¸ºå·¥ç¨‹"åŒå¼•æ“ï¼šä»£ç æ“ä½œçº¦æŸ + æ–‡æ¡£è§„èŒƒçº¦æŸ
- å¯ç‹¬ç«‹éƒ¨ç½²ä¸ºé€šç”¨MCPæœåŠ¡ï¼Œæ‰©å±•åˆ°ä¼ä¸šçº§è¡Œä¸ºæ²»ç†
- å»ºç«‹"åŸåˆ™é©±åŠ¨ > æ¨¡æ¿å¡«ç©º"çš„æ–°èŒƒå¼

### ç›®æ ‡ç”¨æˆ·

- **AIåŠ©æ‰‹**ï¼šéœ€è¦éµå®ˆé¡¹ç›®è§„èŒƒçš„Claude Codeã€Cursorã€Copilot
- **å¼€å‘è€…**ï¼šå¸Œæœ›å›¢é˜Ÿç»Ÿä¸€æ–‡æ¡£é£æ ¼çš„æŠ€æœ¯è´Ÿè´£äºº
- **ä¼ä¸šç»„ç»‡**ï¼šéœ€è¦å¤šé¡¹ç›®è§„èŒƒæ²»ç†çš„ç»„ç»‡æ¶æ„å¸ˆ

---

## ğŸ¯ æˆåŠŸæŒ‡æ ‡

### TPSTå½±å“ï¼ˆä¸»æŒ‡æ ‡ï¼‰

| æŒ‡æ ‡ | åŸºçº¿ | MVPç›®æ ‡ | æœ€ç»ˆç›®æ ‡ |
|------|------|---------|----------|
| **reduced_rework_tokens** | - | -30% | -40% |
| **document_creation_success_rate** | ~60% | 85% | 95% |
| **avg_tokens_per_doc_task** | 1200 | 900 | 750 |

**æµ‹é‡æ–¹å¼**ï¼š
```python
# å¯¹æ¯”å®éªŒï¼šåŒä¸€æ–‡æ¡£ä»»åŠ¡
baseline_tokens = create_doc_without_standards()  # ~1200 tokensï¼ˆåå¤çº æ­£ï¼‰
optimized_tokens = create_doc_with_standards()    # ~750 tokensï¼ˆä¸€æ¬¡æˆåŠŸï¼‰
reduction = (baseline - optimized) / baseline     # 37.5%
```

### è§„èŒƒéµå®ˆæŒ‡æ ‡ï¼ˆè´¨é‡ï¼‰

| æŒ‡æ ‡ | MVPç›®æ ‡ | æœ€ç»ˆç›®æ ‡ |
|------|---------|----------|
| **document_placement_accuracy** | 90% | 95% |
| **naming_convention_adherence** | 90% | 95% |
| **structure_completeness** | 85% | 90% |
| **principle_score_avg** | 0.7 | 0.8 |

### ç”¨æˆ·ä½“éªŒæŒ‡æ ‡

| æŒ‡æ ‡ | MVPç›®æ ‡ |
|------|---------|
| **setup_time** | <5åˆ†é’Ÿï¼ˆinitå‘å¯¼ï¼‰ |
| **false_positive_rate** | <5%ï¼ˆè¯¯æŠ¥è¿‡ä¸¥ï¼‰ |
| **waiver_rate** | <10%ï¼ˆéœ€è¦è±å…ï¼‰ |

---

## ğŸ“¦ åŒ…å«çš„Features

### Feature 1: MCP Standards Service Core
- **Feature ID**: FEATURE-004
- **æè¿°**: å®ç°æ ¸å¿ƒMCPæœåŠ¡ç«¯ç‚¹å’Œæ ‡å‡†å®šä¹‰ç³»ç»Ÿ
- **ä¼°ç®—**: 4äººå¤©
- **çŠ¶æ€**: [Backlog]
- **åŒ…å«å†…å®¹**:
  - `standards.get()` - è·å–åˆå¹¶åçš„é¡¹ç›®è§„èŒƒ
  - `doc.suggest_location()` - æ™ºèƒ½ä½ç½®å»ºè®®
  - `doc.template()` - åŸåˆ™é©±åŠ¨çš„æ¨¡æ¿ç”Ÿæˆ
  - `doc.validate()` - å®æ—¶éªŒè¯å’Œçº æ­£å»ºè®®
  - `.project_standards.yml` æ ‡å‡†æ–‡ä»¶å®šä¹‰

### Feature 2: Git Guard Integration
- **Feature ID**: FEATURE-005
- **æè¿°**: å®ç°pre-commité’©å­å’ŒGitå·¥ä½œæµå®ˆå«
- **ä¼°ç®—**: 2äººå¤©
- **çŠ¶æ€**: [Backlog]
- **åŒ…å«å†…å®¹**:
  - `git.guard.precommit()` - pre-commité’©å­
  - è‡ªåŠ¨é˜»æ­¢ä¸åˆè§„æ–‡æ¡£æäº¤
  - æä¾›ä¸€é”®ä¿®å¤å»ºè®®
  - å®¡è®¡æ—¥å¿—è®°å½•

### Feature 3: Principle-Based Validation
- **Feature ID**: FEATURE-006
- **æè¿°**: å®ç°åŸåˆ™é©±åŠ¨çš„æ™ºèƒ½éªŒè¯ç³»ç»Ÿ
- **ä¼°ç®—**: 3äººå¤©
- **çŠ¶æ€**: [Backlog]
- **åŒ…å«å†…å®¹**:
  - è§„åˆ™å¼•æ“ï¼ˆregex, ç»“æ„æ£€æŸ¥ï¼‰
  - åŸåˆ™è¯„åˆ†ç³»ç»Ÿï¼ˆå°æ¨¡å‹ï¼Œâ‰¤100 tokensï¼‰
  - å¯é…ç½®éªŒè¯å™¨ï¼ˆç»„ç»‡çº§+é¡¹ç›®çº§ï¼‰
  - å—æ§è±å…æœºåˆ¶ï¼ˆ`doc.waive()`ï¼‰

### Feature 4: Standards Composition
- **Feature ID**: FEATURE-007
- **æè¿°**: å®ç°æ ‡å‡†ç»§æ‰¿ã€åˆå¹¶ã€å¯è§†åŒ–ç³»ç»Ÿ
- **ä¼°ç®—**: 1äººå¤©
- **çŠ¶æ€**: [Backlog]
- **åŒ…å«å†…å®¹**:
  - æ ‡å‡†ç»§æ‰¿æœºåˆ¶ï¼ˆç»„ç»‡çº§â†’é¡¹ç›®çº§ï¼‰
  - å†²çªè§£å†³ç­–ç•¥
  - `standards.diff()` - å¯è§†åŒ–å·®å¼‚
  - Initå‘å¯¼ï¼ˆç”Ÿæˆåˆå§‹æ ‡å‡†æ–‡ä»¶ï¼‰

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### æ ¸å¿ƒç»„ä»¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MCP Standards Service           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  standards.get()        â† æ ‡å‡†è§£æ      â”‚
â”‚  doc.suggest_location() â† ä½ç½®æ¨è      â”‚
â”‚  doc.template()         â† æ¨¡æ¿ç”Ÿæˆ      â”‚
â”‚  doc.validate()         â† å®æ—¶éªŒè¯      â”‚
â”‚  git.guard.precommit()  â† Gitå®ˆå«       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       Standards Resolver                â”‚
â”‚  â”œâ”€ Organization defaults               â”‚
â”‚  â”œâ”€ Repository overrides                â”‚
â”‚  â””â”€ Merge + Conflict resolution         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       Validation Engine                 â”‚
â”‚  â”œâ”€ Rule checkers (regex, structure)   â”‚
â”‚  â”œâ”€ Principle scorer (small LM)         â”‚
â”‚  â””â”€ Waiver manager                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       Integration Layer                 â”‚
â”‚  â”œâ”€ Pre-commit hooks                    â”‚
â”‚  â”œâ”€ IDE plugins                         â”‚
â”‚  â””â”€ CI/CD gates                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ‡å‡†æ–‡ä»¶ç¤ºä¾‹

```yaml
# .project_standards.yml
version: 1
extends:
  - "https://org-standards.company/tech.yml"  # å¯é€‰

documents:
  epic:
    location: "docs/product/epics/epic-{num}-{kebab}/"
    naming: "epic-{num}-{kebab}.md"
    required_sections:
      - "ä¸šåŠ¡ä»·å€¼"
      - "æˆåŠŸæŒ‡æ ‡"
      - "Features(3-5)"
    principles:
      - id: "why-over-what"
        desc: "è§£é‡Šä¸ºä»€ä¹ˆï¼Œè€Œä¸åªæ˜¯åˆ—å‡ºåšä»€ä¹ˆ"
        checker:
          type: "regex_presence"
          patterns: ["ä¸šåŠ¡ä»·å€¼", "å½±å“"]

      - id: "tpst-oriented"
        desc: "é‡åŒ–TPSTå½±å“"
        checker:
          type: "regex_presence"
          patterns: ["TPST", "tokens", "tokenæµªè´¹"]

  adr:
    location: "docs/development/architecture/adrs/"
    naming: "{seq:03d}-{kebab}.md"
    required_sections: ["Context", "Decision", "Consequences"]

guards:
  root_allowlist: ["README.md", "CLAUDE.md", "pyproject.toml"]
  doc_dirs: ["docs/"]
  max_new_docs_per_pr: 10

validation:
  strict_mode: true  # devå¯è®¾false
  principle_threshold: 0.6
```

### MCPç«¯ç‚¹è®¾è®¡

#### 1. standards.get()
```json
// Request
{
  "project_path": "/path/to/project",
  "include_inherited": true
}

// Response
{
  "version": "1.0",
  "source": "merged",
  "documents": {...},
  "guards": {...},
  "inherited_from": ["org-defaults", "repo-local"]
}
```

#### 2. doc.suggest_location()
```json
// Request
{
  "doc_type": "epic",
  "title": "Tool Intelligence",
  "project_context": {
    "project_type": "technical_product",
    "team_size": "small",
    "development_stage": "mvp"
  }
}

// Response
{
  "suggested_path": "docs/product/epics/epic-002-tool-intelligence/",
  "naming_pattern": "epic-{num}-{kebab}",
  "required_sections": ["ä¸šåŠ¡ä»·å€¼", "æˆåŠŸæŒ‡æ ‡", "Features"],
  "guiding_principles": [
    {
      "id": "why-over-what",
      "desc": "è§£é‡Šä¸ºä»€ä¹ˆï¼Œè€Œä¸åªæ˜¯åˆ—å‡ºåšä»€ä¹ˆ",
      "example": "âœ… 'é™ä½TPST 30%' vs âŒ 'å®ç°ç¼“å­˜åŠŸèƒ½'"
    },
    {
      "id": "tpst-oriented",
      "desc": "é‡åŒ–TPSTå½±å“",
      "example": "âœ… 'reduce_tokens: 1200â†’750' vs âŒ 'æå‡æ€§èƒ½'"
    }
  ],
  "outline": [
    "## ä¸šåŠ¡ä»·å€¼",
    "## æˆåŠŸæŒ‡æ ‡ï¼ˆTPSTï¼‰",
    "## Featuresï¼ˆ3-5ä¸ªï¼‰",
    "## æŠ€æœ¯æ¶æ„",
    "## é£é™©ä¸å¯¹ç­–ï¼ˆå¯é€‰ï¼‰"
  ]
}
```

#### 3. doc.validate()
```json
// Request
{
  "path": "docs/my-random-doc.md",
  "content_meta": {
    "sections": ["æ¦‚è¿°", "å®ç°"],
    "word_count": 500
  }
}

// Response
{
  "ok": false,
  "violations": [
    {
      "rule": "wrong_location",
      "severity": "error",
      "message": "æ–‡æ¡£å¿…é¡»åœ¨docs/ç›®å½•çš„å­åˆ†ç±»ä¸‹",
      "suggested_fix": "docs/product/specs/my-random-doc.md"
    },
    {
      "rule": "missing_section:ä¸šåŠ¡ä»·å€¼",
      "severity": "error",
      "message": "Epicå¿…é¡»åŒ…å«'ä¸šåŠ¡ä»·å€¼'ç« èŠ‚",
      "hint": "è§£é‡Šä¸ºä»€ä¹ˆåšè¿™ä¸ªï¼Œå¯¹ç”¨æˆ·/ä¸šåŠ¡çš„ä»·å€¼"
    }
  ],
  "principle_scores": {
    "why-over-what": 0.4,  // ä½äºé˜ˆå€¼0.6
    "tpst-oriented": 0.0   // å®Œå…¨ç¼ºå¤±
  },
  "overall_score": 0.2,
  "can_proceed": false
}
```

#### 4. git.guard.precommit()
```json
// Request
{
  "staged_files": [
    "docs/temp.md",
    "docs/product/epics/epic-002-project-standards/README.md"
  ]
}

// Response
{
  "ok": false,
  "blocked_files": [
    {
      "path": "docs/temp.md",
      "reason": "è¿åå‘½åè§„èŒƒ",
      "fix": "é‡å‘½åä¸º docs/knowledge/lessons-learned/temp-notes.md"
    }
  ],
  "allowed_files": [
    "docs/product/epics/epic-002-project-standards/README.md"
  ],
  "action": "abort_commit",
  "message": "1ä¸ªæ–‡ä»¶è¿åè§„èŒƒï¼Œè¯·ä¿®å¤åé‡æ–°æäº¤"
}
```

---

## ğŸ¯ åŸåˆ™è¯„åˆ†æ£€æŸ¥å™¨è¯¦ç»†è®¾è®¡

### è®¾è®¡ç†å¿µ

**æ ¸å¿ƒåŸåˆ™**: è§„åˆ™ä¼˜å…ˆï¼Œå°æ¨¡å‹è¾…åŠ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è§„åˆ™å¼•æ“ï¼ˆRule Engineï¼‰               â”‚  â† ç¡®å®šæ€§æ£€æŸ¥ï¼Œå¿«é€Ÿã€å¯é 
â”‚  â”œâ”€ ä½ç½®éªŒè¯ï¼šregexåŒ¹é…               â”‚
â”‚  â”œâ”€ å‘½åéªŒè¯ï¼špatternåŒ¹é…              â”‚
â”‚  â”œâ”€ ç»“æ„éªŒè¯ï¼šå¿…å¡«ç« èŠ‚æ£€æŸ¥             â”‚
â”‚  â””â”€ æ ¼å¼éªŒè¯ï¼šè¯­æ³•ã€é“¾æ¥æœ‰æ•ˆæ€§         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åŸåˆ™è¯„åˆ†å™¨ï¼ˆPrinciple Scorerï¼‰        â”‚  â† è¯­ä¹‰æ£€æŸ¥ï¼Œâ‰¤100 tokens
â”‚  â”œâ”€ å°æ¨¡å‹è°ƒç”¨ï¼ˆGPT-3.5/Claude Haikuï¼‰â”‚
â”‚  â”œâ”€ è¯„åˆ†ç»´åº¦ï¼šwhy-over-what, tpstç­‰   â”‚
â”‚  â””â”€ é˜ˆå€¼åˆ¤æ–­ï¼šâ‰¥0.6é€šè¿‡                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç­–ç•¥**:
- **90%é è§„åˆ™**ï¼šä½ç½®ã€å‘½åã€ç»“æ„ã€æ ¼å¼ç­‰ç¡®å®šæ€§æ£€æŸ¥
- **10%é æ¨¡å‹**ï¼šè¯­ä¹‰è´¨é‡ã€åŸåˆ™éµå®ˆç­‰éœ€è¦ç†è§£çš„éƒ¨åˆ†
- **å°æ¨¡å‹è¶³å¤Ÿ**ï¼šè¯„åˆ†ä»»åŠ¡ç®€å•ï¼Œæ— éœ€å¤§æ¨¡å‹ï¼ˆé™ä½æˆæœ¬å’Œå»¶è¿Ÿï¼‰

---

### è§„åˆ™å¼•æ“å®ç°

#### 1. ä½ç½®éªŒè¯å™¨

```python
class LocationValidator:
    """ä½ç½®è§„åˆ™éªŒè¯"""
    def __init__(self, standards: ProjectStandards):
        self.standards = standards

    def validate(self, file_path: Path) -> ValidationResult:
        """éªŒè¯æ–‡ä»¶ä½ç½®æ˜¯å¦ç¬¦åˆè§„èŒƒ"""
        # æ£€æŸ¥æ˜¯å¦åœ¨docs/ç›®å½•ä¸‹
        if not str(file_path).startswith("docs/"):
            return ValidationResult(
                ok=False,
                violations=[Violation(
                    rule="wrong_location",
                    severity="error",
                    message="æ–‡æ¡£å¿…é¡»åœ¨docs/ç›®å½•ä¸‹",
                    suggested_fix=f"docs/{file_path.name}"
                )]
            )

        # æ£€æŸ¥æ˜¯å¦åœ¨æ ¹ç›®å½•ç™½åå•ä¸­
        if file_path.parent == Path("."):
            if file_path.name not in self.standards.guards.root_allowlist:
                return ValidationResult(
                    ok=False,
                    violations=[Violation(
                        rule="root_not_allowed",
                        severity="error",
                        message=f"é¡¹ç›®æ ¹ç›®å½•åªå…è®¸: {', '.join(self.standards.guards.root_allowlist)}",
                        suggested_fix=self._suggest_category(file_path)
                    )]
                )

        # æ£€æŸ¥æ–‡æ¡£ç±»å‹åŒ¹é…
        doc_type = self._detect_doc_type(file_path)
        if doc_type:
            expected_location = self.standards.documents[doc_type].location
            if not self._matches_pattern(file_path, expected_location):
                return ValidationResult(
                    ok=False,
                    violations=[Violation(
                        rule=f"wrong_location_for_{doc_type}",
                        severity="error",
                        message=f"{doc_type}å¿…é¡»åœ¨{expected_location}",
                        suggested_fix=self._generate_correct_path(file_path, doc_type)
                    )]
                )

        return ValidationResult(ok=True, violations=[])

    def _detect_doc_type(self, file_path: Path) -> Optional[str]:
        """ä»æ–‡ä»¶åæ£€æµ‹æ–‡æ¡£ç±»å‹"""
        name = file_path.name
        if name.startswith("epic-"):
            return "epic"
        elif re.match(r"\d{3}-", name):
            return "adr"
        elif name.startswith("story-"):
            return "story"
        # ... æ›´å¤šç±»å‹
        return None

    def _suggest_category(self, file_path: Path) -> str:
        """æ ¹æ®æ–‡ä»¶åå»ºè®®åˆ†ç±»"""
        name = file_path.stem.lower()
        if "meeting" in name or "notes" in name:
            return f"docs/knowledge/lessons-learned/{file_path.name}"
        elif "test" in name or "benchmark" in name:
            return f"docs/testing/reports/{file_path.name}"
        else:
            return f"docs/knowledge/research/{file_path.name}"
```

#### 2. ç»“æ„éªŒè¯å™¨

```python
class StructureValidator:
    """æ–‡æ¡£ç»“æ„éªŒè¯"""
    def validate(
        self,
        content: str,
        doc_type: str,
        standards: ProjectStandards
    ) -> ValidationResult:
        """éªŒè¯å¿…å¡«ç« èŠ‚æ˜¯å¦å®Œæ•´"""
        required_sections = standards.documents[doc_type].required_sections

        violations = []
        for section in required_sections:
            # æ”¯æŒæ­£åˆ™æ¨¡å¼åŒ¹é…
            if isinstance(section, str):
                pattern = rf"^##\s+{re.escape(section)}"
            else:
                pattern = section["pattern"]

            if not re.search(pattern, content, re.MULTILINE | re.IGNORECASE):
                violations.append(Violation(
                    rule=f"missing_section:{section}",
                    severity="error",
                    message=f"ç¼ºå°‘å¿…å¡«ç« èŠ‚: {section}",
                    hint=self._get_section_hint(section)
                ))

        return ValidationResult(
            ok=len(violations) == 0,
            violations=violations
        )

    def _get_section_hint(self, section: str) -> str:
        """è¿”å›ç« èŠ‚å¡«å†™æç¤º"""
        hints = {
            "ä¸šåŠ¡ä»·å€¼": "è§£é‡Šä¸ºä»€ä¹ˆåšè¿™ä¸ªåŠŸèƒ½ï¼Œå¯¹ç”¨æˆ·/ä¸šåŠ¡çš„ä»·å€¼",
            "æˆåŠŸæŒ‡æ ‡": "é‡åŒ–çš„éªŒæ”¶æ ‡å‡†ï¼Œå°¤å…¶æ˜¯TPSTç›¸å…³æŒ‡æ ‡",
            "Features": "åˆ—å‡º3-5ä¸ªä¸»è¦åŠŸèƒ½ï¼Œæ¯ä¸ªåŒ…å«æè¿°å’Œä¼°ç®—",
            "Context": "æè¿°éœ€è¦åšå‡ºå†³ç­–çš„æŠ€æœ¯é—®é¢˜æˆ–æŒ‘æˆ˜",
            "Decision": "è¯´æ˜æœ€ç»ˆé€‰æ‹©çš„æŠ€æœ¯æ–¹æ¡ˆå’Œæ ¸å¿ƒç†ç”±",
            "Consequences": "åˆ†ææŠ€æœ¯åæœã€å›¢é˜Ÿåæœã€ä¸šåŠ¡åæœ",
        }
        return hints.get(section, f"å‚è€ƒæ¨¡æ¿å¡«å†™{section}ç« èŠ‚")
```

---

### åŸåˆ™è¯„åˆ†å™¨å®ç°

#### è¯„åˆ†ç»´åº¦å®šä¹‰

```python
from pydantic import BaseModel, Field
from typing import List, Literal

class PrincipleDefinition(BaseModel):
    """åŸåˆ™å®šä¹‰"""
    id: str = Field(..., description="åŸåˆ™ID")
    description: str = Field(..., description="åŸåˆ™æè¿°")
    examples_good: List[str] = Field(default_factory=list, description="æ­£é¢ç¤ºä¾‹")
    examples_bad: List[str] = Field(default_factory=list, description="åé¢ç¤ºä¾‹")
    weight: float = Field(default=1.0, description="æƒé‡")
    threshold: float = Field(default=0.6, description="é€šè¿‡é˜ˆå€¼")

# å†…ç½®åŸåˆ™åº“
BUILTIN_PRINCIPLES = {
    "why-over-what": PrincipleDefinition(
        id="why-over-what",
        description="è§£é‡Šä¸ºä»€ä¹ˆåšï¼Œè€Œä¸åªæ˜¯åˆ—å‡ºåšä»€ä¹ˆã€‚å¼ºè°ƒä¸šåŠ¡ä»·å€¼ã€ç”¨æˆ·å½±å“ã€é—®é¢˜è§£å†³ã€‚",
        examples_good=[
            "âœ… 'é™ä½TPST 30%ï¼Œå‡å°‘APIæˆæœ¬' - æ¸…æ™°çš„ä¸šåŠ¡ä»·å€¼",
            "âœ… 'è§£å†³ç”¨æˆ·é¢‘ç¹è¿”å·¥çš„ç—›ç‚¹' - æ˜ç¡®çš„é—®é¢˜å¯¼å‘",
        ],
        examples_bad=[
            "âŒ 'å®ç°ç¼“å­˜åŠŸèƒ½' - åªè¯´åšä»€ä¹ˆï¼Œæ²¡è¯´ä¸ºä»€ä¹ˆ",
            "âŒ 'æ·»åŠ æ—¥å¿—è®°å½•' - ç¼ºä¹ä¸šåŠ¡ä»·å€¼è¯´æ˜",
        ],
        weight=1.5,  # é«˜æƒé‡
        threshold=0.6
    ),

    "tpst-oriented": PrincipleDefinition(
        id="tpst-oriented",
        description="é‡åŒ–TPSTå½±å“ã€‚å¿…é¡»åŒ…å«å…·ä½“çš„tokenæ•°å­—ã€ç™¾åˆ†æ¯”é™ä½ã€æˆ–æ€§èƒ½æŒ‡æ ‡ã€‚",
        examples_good=[
            "âœ… 'TPSTä»1200é™è‡³750ï¼Œå‡å°‘37%'",
            "âœ… 'æ€è€ƒtokenå æ¯”ä»40%é™è‡³15%'",
        ],
        examples_bad=[
            "âŒ 'æå‡æ€§èƒ½' - æ²¡æœ‰é‡åŒ–æŒ‡æ ‡",
            "âŒ 'ä¼˜åŒ–ä½“éªŒ' - ç¼ºä¹TPSTæ•°æ®",
        ],
        weight=1.5,  # é«˜æƒé‡
        threshold=0.6
    ),

    "actionable-over-abstract": PrincipleDefinition(
        id="actionable-over-abstract",
        description="å…·ä½“å¯æ‰§è¡Œçš„æè¿°ï¼Œè€Œä¸æ˜¯æŠ½è±¡æ¦‚å¿µã€‚åŒ…å«æ¸…æ™°çš„éªŒæ”¶æ ‡å‡†ã€‚",
        examples_good=[
            "âœ… 'safe_editå¿…é¡»å…ˆdry_runï¼Œå±•ç¤ºdiffåæ‰å…è®¸apply'",
            "âœ… 'ä½ç½®å»ºè®®å‡†ç¡®ç‡ â‰¥ 95%'",
        ],
        examples_bad=[
            "âŒ 'æä¾›æ™ºèƒ½å»ºè®®' - å¤ªæŠ½è±¡",
            "âŒ 'ç¡®ä¿é«˜è´¨é‡' - æ²¡æœ‰éªŒæ”¶æ ‡å‡†",
        ],
        weight=1.0,
        threshold=0.5
    ),

    "evidence-based": PrincipleDefinition(
        id="evidence-based",
        description="åŸºäºè¯æ®çš„é™ˆè¿°ã€‚å¼•ç”¨æ•°æ®ã€æµ‹è¯•ç»“æœã€åŸºå‡†å¯¹æ¯”ã€å­¦æœ¯è®ºæ–‡ã€‚",
        examples_good=[
            "âœ… 'åŸºå‡†æµ‹è¯•æ˜¾ç¤ºP95å»¶è¿Ÿé™ä½50%ï¼ˆè§docs/benchmarks/ï¼‰'",
            "âœ… 'å‚è€ƒGraph-of-Thoughtè®ºæ–‡ï¼ˆarXiv:2305.16582ï¼‰'",
        ],
        examples_bad=[
            "âŒ 'åº”è¯¥ä¼šæ›´å¿«' - æ²¡æœ‰è¯æ®",
            "âŒ 'å¤§å®¶éƒ½è¿™ä¹ˆåš' - ç¼ºä¹ä¾æ®",
        ],
        weight=1.0,
        threshold=0.5
    ),
}
```

#### å°æ¨¡å‹è¯„åˆ†å®ç°

```python
import anthropic
from openai import OpenAI

class PrincipleScorer:
    """åŸåˆ™è¯„åˆ†å™¨ï¼ˆä½¿ç”¨å°æ¨¡å‹ï¼‰"""
    def __init__(
        self,
        model: Literal["gpt-3.5-turbo", "claude-haiku"] = "claude-haiku",
        principles: dict[str, PrincipleDefinition] = BUILTIN_PRINCIPLES
    ):
        self.model = model
        self.principles = principles

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        if model.startswith("gpt"):
            self.client = OpenAI()
        else:
            self.client = anthropic.Anthropic()

    def score(
        self,
        content: str,
        doc_type: str,
        principles_to_check: List[str]
    ) -> dict[str, float]:
        """è¯„åˆ†æ–‡æ¡£å†…å®¹ï¼ˆæ‰¹é‡è¯„åˆ†ä»¥èŠ‚çœè°ƒç”¨ï¼‰"""
        # æ„å»ºè¯„åˆ†prompt
        prompt = self._build_scoring_prompt(content, doc_type, principles_to_check)

        # è°ƒç”¨å°æ¨¡å‹
        response = self._call_model(prompt)

        # è§£æè¯„åˆ†ç»“æœ
        scores = self._parse_scores(response, principles_to_check)

        return scores

    def _build_scoring_prompt(
        self,
        content: str,
        doc_type: str,
        principles_to_check: List[str]
    ) -> str:
        """æ„å»ºè¯„åˆ†promptï¼ˆâ‰¤100 tokensç›®æ ‡ï¼‰"""
        # æå–å…³é”®å†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰
        excerpt = content[:500] + ("..." if len(content) > 500 else "")

        # æ„å»ºåŸåˆ™è¯´æ˜
        principles_desc = "\n".join([
            f"- {p_id}: {self.principles[p_id].description}"
            for p_id in principles_to_check
        ])

        prompt = f"""è¯„åˆ†ä»»åŠ¡ï¼šæ£€æŸ¥{doc_type}æ–‡æ¡£æ˜¯å¦éµå®ˆä»¥ä¸‹åŸåˆ™ã€‚

æ–‡æ¡£æ‘˜è¦ï¼š
{excerpt}

è¯„åˆ†åŸåˆ™ï¼š
{principles_desc}

è¯·ä¸ºæ¯ä¸ªåŸåˆ™æ‰“åˆ†ï¼ˆ0.0-1.0ï¼‰ï¼Œåªè¿”å›JSONæ ¼å¼ï¼š
{{"principle_id": score, ...}}

è¯„åˆ†æ ‡å‡†ï¼š
- 1.0: å®Œå…¨ç¬¦åˆï¼Œæœ‰æ¸…æ™°è¯æ®
- 0.6-0.9: åŸºæœ¬ç¬¦åˆï¼Œæœ‰éƒ¨åˆ†è¯æ®
- 0.3-0.5: éƒ¨åˆ†ç¬¦åˆï¼Œè¯æ®ä¸è¶³
- 0.0-0.2: ä¸ç¬¦åˆæˆ–å®Œå…¨ç¼ºå¤±

åªè¿”å›JSONï¼Œæ— éœ€è§£é‡Šã€‚"""

        return prompt

    def _call_model(self, prompt: str) -> str:
        """è°ƒç”¨å°æ¨¡å‹"""
        if self.model == "claude-haiku":
            response = self.client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=200,  # åªéœ€è¦è¿”å›JSONè¯„åˆ†
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text
        else:  # gpt-3.5-turbo
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                max_tokens=200,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content

    def _parse_scores(
        self,
        response: str,
        principles_to_check: List[str]
    ) -> dict[str, float]:
        """è§£ææ¨¡å‹è¿”å›çš„è¯„åˆ†"""
        import json

        try:
            scores = json.loads(response.strip())
            # éªŒè¯å¹¶è§„èŒƒåŒ–è¯„åˆ†
            return {
                p_id: float(scores.get(p_id, 0))
                for p_id in principles_to_check
            }
        except (json.JSONDecodeError, ValueError):
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤ä½åˆ†
            return {p_id: 0.3 for p_id in principles_to_check}
```

#### ç»¼åˆè¯„åˆ†é€»è¾‘

```python
class ComprehensiveValidator:
    """ç»¼åˆéªŒè¯å™¨ï¼ˆè§„åˆ™+åŸåˆ™ï¼‰"""
    def __init__(self, standards: ProjectStandards):
        self.location_validator = LocationValidator(standards)
        self.structure_validator = StructureValidator()
        self.principle_scorer = PrincipleScorer()
        self.standards = standards

    def validate(
        self,
        file_path: Path,
        content: str
    ) -> ValidationResult:
        """ç»¼åˆéªŒè¯ï¼ˆè§„åˆ™ä¼˜å…ˆï¼ŒåŸåˆ™è¾…åŠ©ï¼‰"""
        doc_type = self._detect_doc_type(file_path)

        violations = []
        principle_scores = {}

        # 1. è§„åˆ™éªŒè¯ï¼ˆå¿…é¡»é€šè¿‡ï¼‰
        location_result = self.location_validator.validate(file_path)
        violations.extend(location_result.violations)

        structure_result = self.structure_validator.validate(
            content, doc_type, self.standards
        )
        violations.extend(structure_result.violations)

        # å¦‚æœè§„åˆ™éªŒè¯å¤±è´¥ï¼Œä¸è¿›è¡ŒåŸåˆ™è¯„åˆ†ï¼ˆèŠ‚çœæˆæœ¬ï¼‰
        if violations and all(v.severity == "error" for v in violations):
            return ValidationResult(
                ok=False,
                violations=violations,
                principle_scores={},
                overall_score=0.0,
                can_proceed=False
            )

        # 2. åŸåˆ™è¯„åˆ†ï¼ˆè¯­ä¹‰è´¨é‡ï¼‰
        if doc_type in self.standards.documents:
            doc_standard = self.standards.documents[doc_type]
            principles_to_check = [p.id for p in doc_standard.principles]

            if principles_to_check:
                principle_scores = self.principle_scorer.score(
                    content, doc_type, principles_to_check
                )

                # æ£€æŸ¥æ˜¯å¦ä½äºé˜ˆå€¼
                for p_id, score in principle_scores.items():
                    principle = next(
                        p for p in doc_standard.principles if p.id == p_id
                    )
                    if score < principle.threshold:
                        violations.append(Violation(
                            rule=f"principle:{p_id}",
                            severity="warning",  # åŸåˆ™è¯„åˆ†å¤±è´¥æ˜¯è­¦å‘Šï¼Œä¸æ˜¯é”™è¯¯
                            message=f"åŸåˆ™'{principle.description}'è¯„åˆ†åä½ï¼ˆ{score:.2f} < {principle.threshold}ï¼‰",
                            hint=f"æ­£é¢ç¤ºä¾‹: {principle.examples_good[0]}"
                        ))

        # 3. è®¡ç®—æ€»åˆ†
        overall_score = self._calculate_overall_score(
            violations, principle_scores
        )

        # 4. åˆ¤æ–­æ˜¯å¦å¯ä»¥ç»§ç»­
        can_proceed = (
            len([v for v in violations if v.severity == "error"]) == 0
            and overall_score >= self.standards.validation.principle_threshold
        )

        return ValidationResult(
            ok=can_proceed,
            violations=violations,
            principle_scores=principle_scores,
            overall_score=overall_score,
            can_proceed=can_proceed
        )

    def _calculate_overall_score(
        self,
        violations: List[Violation],
        principle_scores: dict[str, float]
    ) -> float:
        """è®¡ç®—æ€»åˆ†"""
        # è§„åˆ™é”™è¯¯æ‰£åˆ†
        error_penalty = len([v for v in violations if v.severity == "error"]) * 0.3
        warning_penalty = len([v for v in violations if v.severity == "warning"]) * 0.1

        # åŸåˆ™è¯„åˆ†åŠ æƒå¹³å‡
        if principle_scores:
            principle_avg = sum(principle_scores.values()) / len(principle_scores)
        else:
            principle_avg = 0.5  # æ²¡æœ‰åŸåˆ™è¯„åˆ†æ—¶é»˜è®¤ä¸­ç­‰

        # ç»¼åˆè¯„åˆ†
        score = max(0, principle_avg - error_penalty - warning_penalty)
        return round(score, 2)
```

---

### Tokenæˆæœ¬ä¼˜åŒ–

**è¯„åˆ†æˆæœ¬åˆ†æ**:
```python
# å•æ¬¡è¯„åˆ†tokenæ¶ˆè€—
prompt_tokens = 150  # åŒ…å«æ–‡æ¡£æ‘˜è¦+åŸåˆ™è¯´æ˜
completion_tokens = 50  # JSONè¯„åˆ†ç»“æœ

total_per_validation = 200 tokens

# æ¯æ—¥æˆæœ¬ä¼°ç®—ï¼ˆå‡è®¾10æ¬¡æ–‡æ¡£åˆ›å»ºï¼‰
daily_validations = 10
daily_tokens = 10 * 200 = 2000 tokens

# å°æ¨¡å‹æˆæœ¬ï¼ˆClaude Haikuï¼‰
cost_per_1M_tokens = $0.25
daily_cost = 2000 / 1_000_000 * 0.25 = $0.0005

# æœˆæˆæœ¬
monthly_cost = 0.0005 * 30 = $0.015
```

**å¯¹æ¯”å¤§æ¨¡å‹**:
- å¦‚æœä½¿ç”¨Claude Sonnetè¯„åˆ†ï¼šæœˆæˆæœ¬ ~$0.45ï¼ˆ30xå·®è·ï¼‰
- å°æ¨¡å‹è¶³å¤Ÿå‡†ç¡®ï¼ˆè¯„åˆ†ä»»åŠ¡ç®€å•ï¼‰ï¼Œæ— éœ€å¤§æ¨¡å‹

---

### å¯é…ç½®æ€§

#### é¡¹ç›®çº§åŸåˆ™å®šä¹‰

```yaml
# .project_standards.yml
documents:
  epic:
    location: "docs/product/epics/epic-{num}-{kebab}/"
    naming: "epic-{num}-{kebab}.md"
    required_sections:
      - "ä¸šåŠ¡ä»·å€¼"
      - "æˆåŠŸæŒ‡æ ‡"
      - "Features(3-5)"

    # è‡ªå®šä¹‰åŸåˆ™
    principles:
      - id: "why-over-what"
        desc: "è§£é‡Šä¸ºä»€ä¹ˆï¼Œè€Œä¸åªæ˜¯åˆ—å‡ºåšä»€ä¹ˆ"
        checker:
          type: "llm_scorer"  # ä½¿ç”¨å°æ¨¡å‹è¯„åˆ†
          model: "claude-haiku"  # å¯é€‰ï¼šgpt-3.5-turbo
          threshold: 0.6
          weight: 1.5
        examples_good:
          - "âœ… 'é™ä½TPST 30%ï¼Œå‡å°‘APIæˆæœ¬'"
        examples_bad:
          - "âŒ 'å®ç°ç¼“å­˜åŠŸèƒ½'"

      - id: "tpst-oriented"
        desc: "é‡åŒ–TPSTå½±å“"
        checker:
          type: "regex_presence"  # ç®€å•çš„regexæ£€æŸ¥
          patterns: ["TPST", "tokens", "tokenæµªè´¹", "\\d+%"]
        # regexæ£€æŸ¥æ›´å¿«æ›´ä¾¿å®œï¼Œé€‚åˆç¡®å®šæ€§æ£€æŸ¥

validation:
  strict_mode: true  # å¼€å‘é˜¶æ®µå¯è®¾ä¸ºfalseï¼ˆå®½æ¾æ¨¡å¼ï¼‰
  principle_threshold: 0.6  # åŸåˆ™è¯„åˆ†æ€»åˆ†é˜ˆå€¼
  enable_llm_scoring: true  # æ˜¯å¦å¯ç”¨å°æ¨¡å‹è¯„åˆ†ï¼ˆå¯å…³é—­ä»¥èŠ‚çœæˆæœ¬ï¼‰
```

---

### æœ€ä½³å®è·µå»ºè®®

1. **è§„åˆ™ä¼˜å…ˆ**: èƒ½ç”¨regex/patternæ£€æŸ¥çš„ï¼Œä¸ç”¨å°æ¨¡å‹
2. **æ‰¹é‡è¯„åˆ†**: ä¸€æ¬¡è°ƒç”¨è¯„ä¼°å¤šä¸ªåŸåˆ™ï¼ŒèŠ‚çœAPIè°ƒç”¨
3. **ç¼“å­˜ç»“æœ**: åŒä¸€æ–‡æ¡£çŸ­æœŸå†…ä¸é‡å¤è¯„åˆ†
4. **å®½æ¾æ¨¡å¼**: å¼€å‘é˜¶æ®µé™ä½é˜ˆå€¼ï¼Œé¿å…è¿‡åº¦æ‰“æ–­
5. **è±å…æœºåˆ¶**: ç‰¹æ®Šæƒ…å†µå…è®¸è±å…ï¼Œè®°å½•å®¡è®¡æ—¥å¿—

---

## ğŸ”— ä¾èµ–å…³ç³»

### ä¾èµ–çš„Epic
- **Epic-001: è¡Œä¸ºçº¦æŸç³»ç»Ÿ** - å…±äº«"è¡Œä¸ºå·¥ç¨‹"åº•ç›˜å’ŒExecutionPlanéªŒè¯æ¨¡å¼

### ä¸Epic-001çš„å…³ç³»

| ç»´åº¦ | Epic-001 | Epic-002 |
|------|----------|----------|
| **çº¦æŸå¯¹è±¡** | ä»£ç æ“ä½œï¼ˆsearch, edit, execï¼‰ | æ–‡æ¡£æ“ä½œï¼ˆcreate, structureï¼‰ |
| **çº¦æŸæ–¹å¼** | ExecutionPlan + dry_run | DocPlan + validate |
| **ç‰©ç†åˆ é™¤è·¯å¾„** | ç¦æ­¢ç›´æ¥æ‰§è¡Œï¼Œå¿…é¡»å…ˆé¢„è§ˆ | ç¦æ­¢ç›´æ¥åˆ›å»ºï¼Œå¿…é¡»å…ˆéªŒè¯ |
| **éªŒè¯æœºåˆ¶** | pre_conditions + rollback | location + structure + principles |
| **TPSTå½±å“** | å‡å°‘ç›²ç›®é‡è¯• | å‡å°‘æ–‡æ¡£è¿”å·¥ |

**å…±äº«åŸºç¡€è®¾æ–½**ï¼š
- Pydantic validationæ¨¡å¼
- MCP serviceæ¶æ„
- dry_run â†’ validate â†’ executeæµç¨‹
- å®¡è®¡æ—¥å¿—ç³»ç»Ÿ

### è¢«ä¾èµ–çš„Feature
- Epic-003: å¯èƒ½éœ€è¦æ‰©å±•åˆ°ä»£ç è§„èŒƒçº¦æŸ
- ä¼ä¸šçº§è¡Œä¸ºæ²»ç†ä¸­å¿ƒï¼ˆé•¿æœŸè§„åˆ’ï¼‰

---

## ğŸ“Š æ—¶é—´çº¿

### é¢„è®¡æ—¶é—´
- **å¼€å§‹æ—¥æœŸ**: 2025-11-04ï¼ˆEpic-001å®Œæˆåï¼‰
- **ç»“æŸæ—¥æœŸ**: 2025-11-15
- **æ€»å·¥ä½œé‡**: 10äººå¤© (2å‘¨ MVP)

### é‡Œç¨‹ç¢‘

#### Week 1: æ ¸å¿ƒæœåŠ¡å®ç°
- [ ] Feature-004 å®Œæˆï¼šMCPç«¯ç‚¹å’Œæ ‡å‡†ç³»ç»Ÿ - 2025-11-08
  - [ ] Story-004: standards.get() + Resolver
  - [ ] Story-005: doc.suggest_location()
  - [ ] Story-006: doc.template() åŸåˆ™é©±åŠ¨ç”Ÿæˆ
  - [ ] Story-007: doc.validate() æ ¸å¿ƒéªŒè¯

#### Week 2: Gité›†æˆå’ŒéªŒè¯ä¼˜åŒ–
- [ ] Feature-005 å®Œæˆï¼šGitå®ˆå«é›†æˆ - 2025-11-12
  - [ ] Story-008: pre-commité’©å­
  - [ ] Story-009: ä¸€é”®ä¿®å¤å»ºè®®
- [ ] Feature-006 å®Œæˆï¼šåŸåˆ™è¯„åˆ†ç³»ç»Ÿ - 2025-11-15
  - [ ] Story-010: è§„åˆ™å¼•æ“
  - [ ] Story-011: åŸåˆ™è¯„åˆ†ï¼ˆå°æ¨¡å‹ï¼‰
  - [ ] Story-012: è±å…æœºåˆ¶

### æ¼”ç¤ºåœºæ™¯
**è‹±é›„åœºæ™¯**ï¼šAIåŠ©æ‰‹å°è¯•åˆ›å»ºæ–‡æ¡£
1. AI: "æˆ‘è¦åˆ›å»ºä¸€ä¸ªEpicå…³äºå·¥å…·æ™ºèƒ½"
2. è°ƒç”¨ `doc.suggest_location()` â†’ è¿”å›å»ºè®®è·¯å¾„å’ŒåŸåˆ™
3. AI: æŒ‰ç…§åŸåˆ™åˆ›å»ºæ–‡æ¡£
4. è°ƒç”¨ `doc.validate()` â†’ æ£€æµ‹ç¼ºå°‘"TPSTæŒ‡æ ‡"ç« èŠ‚
5. AI: è¡¥å……ç¼ºå¤±ç« èŠ‚
6. è°ƒç”¨ `doc.validate()` â†’ âœ… é€šè¿‡
7. Gitæäº¤ â†’ pre-commité’©å­è‡ªåŠ¨éªŒè¯ â†’ âœ… å…è®¸æäº¤

**å¯¹æ¯”TPST**ï¼š
- æ— çº¦æŸï¼š1200 tokensï¼ˆ3æ¬¡è¿”å·¥ï¼‰
- æœ‰çº¦æŸï¼š750 tokensï¼ˆé¦–æ¬¡æˆåŠŸï¼‰
- **é™ä½37.5%**

---

## ğŸ›¡ï¸ é£é™©ä¸å¯¹ç­–

### æŠ€æœ¯é£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | å¯¹ç­– | è´Ÿè´£äºº |
|------|------|------|------|--------|
| è§„åˆ™è¿‡äºåƒµåŒ– | High | Medium | æä¾›waiveræœºåˆ¶ï¼Œè®°å½•å®¡è®¡ç—•è¿¹ | Team |
| å¤šé¡¹ç›®å·®å¼‚å¤§ | Medium | High | æ ‡å‡†ç»§æ‰¿+å±€éƒ¨è¦†ç›–ï¼ŒResolveråˆå¹¶ | Team |
| åŸåˆ™è¯„åˆ†ä¸å‡† | Medium | Medium | ä¼˜å…ˆç”¨è§„åˆ™å¼•æ“ï¼Œå°æ¨¡å‹ä»…è¾…åŠ© | Team |
| æ€§èƒ½å¼€é”€ | Low | Low | ç¼“å­˜æ ‡å‡†è§£æï¼Œå¼‚æ­¥éªŒè¯ | Team |

### è¿›åº¦é£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | å¯¹ç­– | è´Ÿè´£äºº |
|------|------|------|------|--------|
| ä¸Epic-001æ—¶é—´é‡å  | Medium | Low | Epic-001ä¼˜å…ˆï¼Œ002å¹¶è¡Œå‡†å¤‡ | Team |
| æ ‡å‡†å®šä¹‰éš¾ä»¥æ”¶æ•› | High | Medium | å…ˆå®ç°3ç§æ–‡æ¡£ç±»å‹ï¼ˆepic/adr/storyï¼‰ | Team |

### ç”¨æˆ·ä½“éªŒé£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | å¯¹ç­– | è´Ÿè´£äºº |
|------|------|------|------|--------|
| ä¸Šæ‰‹æˆæœ¬é«˜ | Medium | Medium | æä¾›initå‘å¯¼ï¼Œå†…ç½®3-5å¥—æ¨¡æ¿ | Team |
| è¯¯æŠ¥ç‡é«˜ | High | Medium | åˆæœŸå®½æ¾æ¨¡å¼ï¼Œé€æ­¥æ”¶ç´§ | Team |

---

## ğŸ”„ é•¿æœŸæ¼”è¿›è·¯çº¿

### Phase 1: æ–‡æ¡£è§„èŒƒçº¦æŸï¼ˆMVP - 2å‘¨ï¼‰
âœ… å½“å‰EpicèŒƒå›´
- ä½ç½®ã€å‘½åã€ç»“æ„ã€å¿…å¡«ç« èŠ‚éªŒè¯
- Pre-commitå®ˆå«
- åŸåˆ™é©±åŠ¨çš„æŒ‡å¯¼

### Phase 2: ä»£ç è¡Œä¸ºè§„èŒƒï¼ˆMonth 2ï¼‰
ğŸ“‹ æ‰©å±•åˆ°ä»£ç æäº¤è§„èŒƒ
- **Conventional Commits** æ ¡éªŒä¸å»ºè®®
- **PRæ¨¡æ¿/æ£€æŸ¥æ¸…å•** è‡ªåŠ¨åŒ–
  - å¿…é¡»åŒ…å«ï¼šéªŒè¯ç»“æœã€TPSTå½±å“è¯„ä¼°
- **ADRæµç¨‹å®ˆå«**
  - å‘½åã€ç´¢å¼•ã€äº¤å‰å¼•ç”¨è‡ªåŠ¨åŒ–
- **Commit messageè´¨é‡è¯„åˆ†**

### Phase 3: CI/CDè¡Œä¸ºæ²»ç†ï¼ˆMonth 3ï¼‰
ğŸš€ ä¼ä¸šçº§æ²»ç†
- **CI/CD Gates**ï¼šä¸åˆè§„ç›´æ¥fail
- **å®¡è®¡æŠ¥å‘Š**ï¼š
  - è§„èŒƒéµå®ˆåº¦è¶‹åŠ¿
  - TPSTå½±å“åˆ†æ
  - è¿”å·¥ç‡çƒ­åŠ›å›¾
- **ç»„ç»‡çº§æ ‡å‡†æ³¨å†Œè¡¨**
  - ä¸­å¿ƒåŒ–ç®¡ç†
  - ä»“åº“ç»§æ‰¿ç­–ç•¥
  - å·®å¼‚å¯è§†åŒ–

### Phase 4: é€šç”¨è¡Œä¸ºå·¥ç¨‹å¹³å°ï¼ˆé•¿æœŸï¼‰
ğŸŒŸ äº§å“åŒ–
- æ”¯æŒä»»æ„è§„èŒƒç±»å‹ï¼ˆAPIè®¾è®¡ã€æµ‹è¯•è¦†ç›–ç‡ï¼‰
- æ’ä»¶ç³»ç»Ÿï¼ˆè‡ªå®šä¹‰éªŒè¯å™¨ï¼‰
- SaaSåŒ–éƒ¨ç½²ï¼ˆä¼ä¸šå¤šç§Ÿæˆ·ï¼‰
- å¼€æºç¤¾åŒºç‰ˆæœ¬

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### æµ‹è¯•èŒƒå›´
- MCPç«¯ç‚¹çš„è¯·æ±‚/å“åº”æ­£ç¡®æ€§
- æ ‡å‡†è§£æå’Œåˆå¹¶é€»è¾‘
- éªŒè¯å¼•æ“çš„è§„åˆ™è¦†ç›–
- Pre-commité’©å­é›†æˆ
- åŸåˆ™è¯„åˆ†å‡†ç¡®æ€§

### æµ‹è¯•ç±»å‹
- [x] å•å…ƒæµ‹è¯• - æ¯ä¸ªMCPç«¯ç‚¹ç‹¬ç«‹æµ‹è¯•
- [x] é›†æˆæµ‹è¯• - å®Œæ•´çš„å»ºè®®â†’éªŒè¯â†’å®ˆå«æµç¨‹
- [x] TPSTåŸºå‡†æµ‹è¯• - å¯¹æ¯”æœ‰/æ— çº¦æŸçš„tokenæ¶ˆè€—
- [ ] ç”¨æˆ·ä½“éªŒæµ‹è¯• - å®é™…æ–‡æ¡£åˆ›å»ºåœºæ™¯

### æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡
- æ ¸å¿ƒæ¨¡å—: 95%
- æ•´ä½“: 90%

---

## ğŸ“ å®ç°å¤‡æ³¨

### è®¾è®¡å†³ç­–

1. **ä¸ºä»€ä¹ˆç‹¬ç«‹MCPæœåŠ¡è€Œä¸æ˜¯é›†æˆåˆ°Serenaï¼Ÿ**
   - æ›´é€šç”¨ï¼šé€‚ç”¨äºä»»ä½•é¡¹ç›®ï¼Œä¸é™äºSerenaç”¨æˆ·
   - å¯ç»„åˆï¼šå¯ä¸å…¶ä»–MCPæœåŠ¡é…åˆä½¿ç”¨
   - ç‹¬ç«‹éƒ¨ç½²ï¼šä¼ä¸šå¯å•ç‹¬éƒ¨ç½²æ ‡å‡†æœåŠ¡

2. **ä¸ºä»€ä¹ˆåŸåˆ™é©±åŠ¨è€Œä¸æ˜¯å›ºå®šæ¨¡æ¿ï¼Ÿ**
   - çµæ´»æ€§ï¼šä¸åŒé¡¹ç›®ç±»å‹æœ‰ä¸åŒéœ€æ±‚
   - å¯ç†è§£æ€§ï¼šAIç†è§£"ä¸ºä»€ä¹ˆ"è€Œä¸åªæ˜¯"å¡«ç©º"
   - å¯æ‰©å±•æ€§ï¼šæ·»åŠ æ–°åŸåˆ™æ— éœ€æ”¹æ¨¡æ¿

3. **ä¸ºä»€ä¹ˆä½¿ç”¨å°æ¨¡å‹åšåŸåˆ™è¯„åˆ†ï¼Ÿ**
   - Tokenæ•ˆç‡ï¼šè¯„åˆ†â‰¤100 tokensï¼Œä¸è®©å¤§æ¨¡å‹é•¿ç¯‡åˆ¤è¯»
   - é€Ÿåº¦ï¼šå¿«é€Ÿåé¦ˆï¼Œä¸é˜»å¡åˆ›å»ºæµç¨‹
   - æˆæœ¬ï¼šå°æ¨¡å‹æˆæœ¬ä½ï¼Œå¯é¢‘ç¹è°ƒç”¨

4. **ä¸ºä»€ä¹ˆæä¾›waiveræœºåˆ¶ï¼Ÿ**
   - é¿å…è¿‡åº¦åƒµåŒ–ï¼šç‰¹æ®Šæƒ…å†µéœ€è¦è±å…
   - å®¡è®¡é€æ˜ï¼šè®°å½•è±å…åŸå› å’Œå†³ç­–è€…
   - å¹³è¡¡æ§åˆ¶ä¸çµæ´»æ€§

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

### å†…éƒ¨æ–‡æ¡£
- [Epic 001: è¡Œä¸ºçº¦æŸç³»ç»Ÿ](../epic-001-behavior-constraints/README.md)
- [äº§å“å®šä¹‰ v1.0](../../definition/product-definition-v1.md)
- [TPSTæŒ‡æ ‡ä½“ç³»](../../../development/architecture/behavior-engineering.md)

### å¤–éƒ¨å‚è€ƒ
- [MCP Protocol Specification](https://spec.modelcontextprotocol.io/)
- [Conventional Commits](https://www.conventionalcommits.org/)
- [ADR (Architecture Decision Records)](https://adr.github.io/)

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³è¡ŒåŠ¨ï¼ˆæœ¬å‘¨ï¼‰
1. âœ… åˆ›å»ºEpic-002æ–‡æ¡£ï¼ˆå½“å‰æ–‡æ¡£ï¼‰
2. ğŸ“‹ åˆ›å»ºæŠ€æœ¯æ¶æ„è®¾è®¡æ–‡æ¡£
3. ğŸ“‹ åˆ›å»ºFeature-004è¯¦ç»†è§„æ ¼
4. ğŸ“‹ åˆ¶å®šå¹¶è¡Œå¼€å‘è®¡åˆ’

### çŸ­æœŸè¡ŒåŠ¨ï¼ˆ2å‘¨å†…ï¼‰
1. å®ç°æ ¸å¿ƒMCPç«¯ç‚¹ï¼ˆFeature-004ï¼‰
2. å»ºç«‹åŸºå‡†æµ‹è¯•ï¼ˆTPSTå¯¹æ¯”ï¼‰
3. å®ŒæˆMVPæ¼”ç¤ºåœºæ™¯

### é—®é¢˜å¾…æ¾„æ¸…
1. æ˜¯å¦ä¸Epic-001å¹¶è¡Œå¼€å‘ï¼Ÿè¿˜æ˜¯é¡ºåºå¼€å‘ï¼Ÿ
2. åˆå§‹æ ‡å‡†æ–‡ä»¶åº”è¯¥åŒ…å«å“ªäº›æ–‡æ¡£ç±»å‹ï¼Ÿ
3. åŸåˆ™è¯„åˆ†ä½¿ç”¨å“ªä¸ªå°æ¨¡å‹ï¼Ÿï¼ˆGPT-3.5-turbo? Claude Haiku?ï¼‰

---

**æœ€åæ›´æ–°**: 2025-10-27
**æ›´æ–°äºº**: EvolvAI Team
