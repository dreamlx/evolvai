# Project Standards MCP Service - Technical Architecture

**æ–‡æ¡£ç±»å‹**: Technical Architecture
**å…³è”Epic**: [Epic-002: é¡¹ç›®è§„èŒƒå³æœåŠ¡](../../product/epics/epic-002-project-standards/README.md)
**åˆ›å»ºæ—¥æœŸ**: 2025-10-27
**çŠ¶æ€**: [DRAFT]

---

## ğŸ“‹ æ¶æ„æ¦‚è§ˆ

### ç³»ç»Ÿå®šä½

**Project Standards MCP Service** æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„MCPæœåŠ¡ï¼Œæä¾›é¡¹ç›®è§„èŒƒçš„"å¯æ‰§è¡Œçº¦æŸ"èƒ½åŠ›ã€‚

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- ğŸš« **ç‰©ç†åˆ é™¤é”™è¯¯è·¯å¾„**ï¼šAIæ— æ³•åˆ›å»ºä¸åˆè§„æ–‡æ¡£
- ğŸ“ **åŸåˆ™é©±åŠ¨æŒ‡å¯¼**ï¼šæ™ºèƒ½å»ºè®®è€Œéæ­»æ¿æ¨¡æ¿
- ğŸ”„ **æ ‡å‡†ç»§æ‰¿ä¸åˆå¹¶**ï¼šç»„ç»‡çº§+é¡¹ç›®çº§çµæ´»ç»„åˆ
- ğŸ¯ **Tokenæ•ˆç‡ä¼˜åŒ–**ï¼šå‡å°‘æ–‡æ¡£è¿”å·¥ï¼Œé™ä½TPST

### æ¶æ„åˆ†å±‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AI Clients Layer                     â”‚
â”‚  (Claude Code, Cursor, Copilot, Custom Agents)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ MCP Protocol
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MCP Server Interface                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  standards.get()        doc.suggest_location()  â”‚ â”‚
â”‚  â”‚  doc.template()         doc.validate()          â”‚ â”‚
â”‚  â”‚  git.guard.precommit()  doc.waive()             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Business Logic Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Standards  â”‚  â”‚  Validation  â”‚  â”‚    Git     â”‚ â”‚
â”‚  â”‚   Resolver   â”‚  â”‚    Engine    â”‚  â”‚  Guardian  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Data & Config Layer                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Organization â”‚  â”‚   Project    â”‚  â”‚   Cache    â”‚ â”‚
â”‚  â”‚  Standards   â”‚  â”‚  Standards   â”‚  â”‚   Store    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ æ ¸å¿ƒç»„ä»¶è®¾è®¡

### 1. Standards Resolver

**èŒè´£**ï¼šè§£æã€åˆå¹¶ã€éªŒè¯æ ‡å‡†å®šä¹‰

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
```python
class StandardsResolver:
    """æ ‡å‡†è§£æå™¨"""

    def resolve(self, project_path: Path) -> ResolvedStandards:
        """è§£æå¹¶åˆå¹¶æ ‡å‡†

        ä¼˜å…ˆçº§ï¼ˆä½â†’é«˜ï¼‰ï¼š
        1. Built-in defaults
        2. Organization standards (via URL)
        3. Repository .project_standards.yml
        4. Environment overrides (dev/prod)
        """

    def merge_standards(
        self,
        base: Standards,
        override: Standards
    ) -> ResolvedStandards:
        """åˆå¹¶æ ‡å‡†ï¼Œå¤„ç†å†²çª"""

    def validate_schema(self, standards: dict) -> ValidationResult:
        """éªŒè¯æ ‡å‡†æ–‡ä»¶æ ¼å¼"""
```

**æ ‡å‡†æ–‡ä»¶Schema**ï¼š
```python
from pydantic import BaseModel, Field, HttpUrl
from typing import List, Optional, Dict, Literal

class PrincipleChecker(BaseModel):
    """åŸåˆ™æ£€æŸ¥å™¨å®šä¹‰"""
    type: Literal["regex_presence", "regex_absence", "llm_score"]
    patterns: Optional[List[str]] = None
    model: Optional[str] = None  # For llm_score
    threshold: Optional[float] = None

class Principle(BaseModel):
    """åŸåˆ™å®šä¹‰"""
    id: str = Field(..., description="åŸåˆ™å”¯ä¸€æ ‡è¯†")
    desc: str = Field(..., description="åŸåˆ™æè¿°")
    checker: PrincipleChecker
    examples: Optional[Dict[str, str]] = None  # {"good": "âœ… ç¤ºä¾‹", "bad": "âŒ åä¾‹"}

class DocumentStandard(BaseModel):
    """æ–‡æ¡£ç±»å‹æ ‡å‡†"""
    location: str = Field(..., description="ä½ç½®æ¨¡å¼ï¼Œæ”¯æŒå˜é‡ {num}, {kebab}")
    naming: str = Field(..., description="å‘½åæ¨¡å¼")
    required_sections: List[str] = Field(default_factory=list)
    optional_sections: Optional[List[str]] = None
    principles: List[Principle] = Field(default_factory=list)

class GuardConfig(BaseModel):
    """å®ˆå«é…ç½®"""
    root_allowlist: List[str] = Field(
        default_factory=lambda: ["README.md", "CLAUDE.md", "LICENSE"]
    )
    doc_dirs: List[str] = Field(default_factory=lambda: ["docs/"])
    max_new_docs_per_pr: int = 10
    strict_mode: bool = True

class ValidationConfig(BaseModel):
    """éªŒè¯é…ç½®"""
    principle_threshold: float = Field(default=0.6, ge=0.0, le=1.0)
    strict_mode: bool = True
    waiver_required_roles: Optional[List[str]] = None

class ProjectStandards(BaseModel):
    """é¡¹ç›®æ ‡å‡†å®šä¹‰"""
    version: str = "1.0"
    extends: Optional[List[HttpUrl | str]] = None
    documents: Dict[str, DocumentStandard]
    guards: GuardConfig = Field(default_factory=GuardConfig)
    validation: ValidationConfig = Field(default_factory=ValidationConfig)
```

**æ ‡å‡†ç»§æ‰¿ä¸åˆå¹¶é€»è¾‘**ï¼š
```python
def merge_standards(base: ProjectStandards, override: ProjectStandards) -> ProjectStandards:
    """
    åˆå¹¶æ ‡å‡†ï¼Œoverrideä¼˜å…ˆçº§é«˜äºbase

    åˆå¹¶è§„åˆ™ï¼š
    - documents: æŒ‰doc_typeåˆå¹¶ï¼Œoverrideå®Œå…¨æ›¿æ¢base
    - guards: å­—æ®µçº§åˆå¹¶ï¼Œåˆ—è¡¨è¿½åŠ 
    - validation: overrideå­—æ®µæ›¿æ¢baseå­—æ®µ
    - principles: æŒ‰principle.idåˆå¹¶ï¼Œoverrideæ›¿æ¢base
    """
    merged_documents = {**base.documents}
    for doc_type, doc_std in override.documents.items():
        if doc_type in merged_documents:
            # åŸåˆ™æŒ‰IDåˆå¹¶
            base_principles = {p.id: p for p in merged_documents[doc_type].principles}
            override_principles = {p.id: p for p in doc_std.principles}
            merged_principles = {**base_principles, **override_principles}

            # åˆ›å»ºæ–°çš„DocumentStandard
            merged_documents[doc_type] = doc_std.model_copy(update={
                "principles": list(merged_principles.values())
            })
        else:
            merged_documents[doc_type] = doc_std

    return ProjectStandards(
        version=override.version,
        documents=merged_documents,
        guards=merge_guards(base.guards, override.guards),
        validation=override.validation or base.validation
    )
```

---

### 2. Validation Engine

**èŒè´£**ï¼šæ‰§è¡Œè§„åˆ™æ£€æŸ¥å’ŒåŸåˆ™è¯„åˆ†

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
```python
class ValidationEngine:
    """éªŒè¯å¼•æ“"""

    def __init__(self, standards: ResolvedStandards):
        self.standards = standards
        self.rule_checkers = self._init_rule_checkers()
        self.principle_scorer = PrincipleScorer()

    def validate(
        self,
        doc_type: str,
        path: Path,
        content_meta: DocumentMeta
    ) -> ValidationResult:
        """
        å®Œæ•´éªŒè¯æ–‡æ¡£

        éªŒè¯é¡ºåºï¼š
        1. ä½ç½®éªŒè¯ï¼ˆlocation patternï¼‰
        2. å‘½åéªŒè¯ï¼ˆnaming patternï¼‰
        3. ç»“æ„éªŒè¯ï¼ˆrequired sectionsï¼‰
        4. åŸåˆ™è¯„åˆ†ï¼ˆprinciplesï¼‰
        """
        violations = []

        # 1. ä½ç½®éªŒè¯
        expected_location = self._expand_pattern(
            self.standards.documents[doc_type].location,
            context={"num": extract_number(path), ...}
        )
        if not path.match(expected_location):
            violations.append(Violation(
                rule="wrong_location",
                severity="error",
                message=f"æ–‡æ¡£ä½ç½®ä¸æ­£ç¡®",
                suggested_fix=expected_location
            ))

        # 2. å‘½åéªŒè¯
        expected_name = self._expand_pattern(
            self.standards.documents[doc_type].naming,
            context={...}
        )
        if path.name != expected_name:
            violations.append(Violation(
                rule="wrong_naming",
                severity="error",
                message=f"æ–‡æ¡£å‘½åä¸ç¬¦åˆè§„èŒƒ",
                suggested_fix=expected_name
            ))

        # 3. ç»“æ„éªŒè¯
        required_sections = self.standards.documents[doc_type].required_sections
        missing_sections = set(required_sections) - set(content_meta.sections)
        for section in missing_sections:
            violations.append(Violation(
                rule=f"missing_section:{section}",
                severity="error",
                message=f"ç¼ºå°‘å¿…å¡«ç« èŠ‚ï¼š{section}",
                hint=self._get_section_hint(doc_type, section)
            ))

        # 4. åŸåˆ™è¯„åˆ†
        principle_scores = {}
        for principle in self.standards.documents[doc_type].principles:
            score = self._check_principle(principle, content_meta)
            principle_scores[principle.id] = score

            if score < self.standards.validation.principle_threshold:
                violations.append(Violation(
                    rule=f"principle:{principle.id}",
                    severity="warning",
                    message=f"åŸåˆ™'{principle.desc}'å¾—åˆ†è¿‡ä½: {score:.2f}",
                    hint=self._get_principle_hint(principle)
                ))

        overall_score = sum(principle_scores.values()) / len(principle_scores) if principle_scores else 1.0

        return ValidationResult(
            ok=len([v for v in violations if v.severity == "error"]) == 0,
            violations=violations,
            principle_scores=principle_scores,
            overall_score=overall_score,
            can_proceed=overall_score >= self.standards.validation.principle_threshold
        )
```

**åŸåˆ™æ£€æŸ¥å™¨å®ç°**ï¼š
```python
class PrincipleScorer:
    """åŸåˆ™è¯„åˆ†å™¨"""

    def score_regex_presence(
        self,
        patterns: List[str],
        content: str
    ) -> float:
        """åŸºäºæ­£åˆ™åŒ¹é…çš„è¯„åˆ†"""
        matches = sum(1 for p in patterns if re.search(p, content, re.IGNORECASE))
        return min(matches / len(patterns), 1.0)

    def score_with_llm(
        self,
        principle: Principle,
        content_meta: DocumentMeta
    ) -> float:
        """ä½¿ç”¨å°æ¨¡å‹è¯„åˆ†ï¼ˆâ‰¤100 tokensï¼‰"""
        prompt = f"""
        è¯„ä¼°æ–‡æ¡£æ˜¯å¦ç¬¦åˆåŸåˆ™ï¼š{principle.desc}

        æ–‡æ¡£å…ƒä¿¡æ¯ï¼š
        - æ ‡é¢˜: {content_meta.title}
        - ç« èŠ‚: {", ".join(content_meta.sections)}
        - å…³é”®è¯: {", ".join(content_meta.keywords)}

        è¯„åˆ†æ ‡å‡†ï¼š
        - 1.0: å®Œå…¨ç¬¦åˆåŸåˆ™
        - 0.6-0.9: åŸºæœ¬ç¬¦åˆï¼Œå¯æ”¹è¿›
        - 0.0-0.5: ä¸ç¬¦åˆåŸåˆ™

        åªè¿”å›æ•°å­—è¯„åˆ†ï¼ˆ0.0-1.0ï¼‰
        """

        # è°ƒç”¨å°æ¨¡å‹ï¼ˆGPT-3.5-turboæˆ–Claude Haikuï¼‰
        response = self.llm_client.complete(
            prompt=prompt,
            model=principle.checker.model or "gpt-3.5-turbo",
            max_tokens=10,
            temperature=0.0
        )

        try:
            score = float(response.strip())
            return max(0.0, min(1.0, score))
        except ValueError:
            logger.warning(f"Invalid LLM score response: {response}")
            return 0.0
```

---

### 3. Location Suggester

**èŒè´£**ï¼šæ™ºèƒ½æ¨èæ–‡æ¡£ä½ç½®å’Œç»“æ„

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
```python
class LocationSuggester:
    """ä½ç½®å»ºè®®å™¨"""

    def suggest(
        self,
        doc_type: str,
        title: str,
        project_context: ProjectContext
    ) -> LocationSuggestion:
        """
        åŸºäºä¸Šä¸‹æ–‡æ¨èä½ç½®

        è€ƒè™‘å› ç´ ï¼š
        - æ–‡æ¡£ç±»å‹ï¼ˆepic, feature, story, adrï¼‰
        - é¡¹ç›®ç±»å‹ï¼ˆtechnical_product, open_source, enterpriseï¼‰
        - å›¢é˜Ÿè§„æ¨¡ï¼ˆå½±å“æ–‡æ¡£ç²’åº¦ï¼‰
        - å¼€å‘é˜¶æ®µï¼ˆmvp, growth, matureï¼‰
        """
        doc_standard = self.standards.documents[doc_type]

        # ç”Ÿæˆè·¯å¾„
        context_vars = self._generate_context_vars(title, project_context)
        suggested_path = self._expand_pattern(
            doc_standard.location,
            context_vars
        )

        # ç”ŸæˆæŒ‡å¯¼åŸåˆ™
        guiding_principles = self._adapt_principles(
            doc_standard.principles,
            project_context
        )

        # ç”Ÿæˆoutline
        outline = self._generate_outline(
            doc_type,
            doc_standard.required_sections,
            doc_standard.optional_sections,
            project_context
        )

        return LocationSuggestion(
            suggested_path=suggested_path,
            naming_pattern=doc_standard.naming,
            required_sections=doc_standard.required_sections,
            guiding_principles=guiding_principles,
            outline=outline,
            examples=self._get_examples(doc_type)
        )

    def _adapt_principles(
        self,
        principles: List[Principle],
        context: ProjectContext
    ) -> List[AdaptedPrinciple]:
        """æ ¹æ®é¡¹ç›®ä¸Šä¸‹æ–‡è°ƒæ•´åŸåˆ™"""
        adapted = []
        for principle in principles:
            # æ ¹æ®é¡¹ç›®ç±»å‹è°ƒæ•´ç¤ºä¾‹
            if context.project_type == "technical_product":
                examples = {
                    "good": f"âœ… {principle.id}: é‡åŒ–TPSTå½±å“",
                    "bad": f"âŒ {principle.id}: åªæè¿°åŠŸèƒ½ä¸è¯´å½±å“"
                }
            elif context.project_type == "open_source":
                examples = {
                    "good": f"âœ… {principle.id}: è¯´æ˜ç¤¾åŒºä»·å€¼",
                    "bad": f"âŒ {principle.id}: åªå…³æ³¨æŠ€æœ¯å®ç°"
                }

            adapted.append(AdaptedPrinciple(
                id=principle.id,
                desc=principle.desc,
                examples=examples,
                importance=self._calculate_importance(principle, context)
            ))

        return adapted
```

---

### 4. Git Guardian

**èŒè´£**ï¼šPre-commité’©å­å’ŒGitå·¥ä½œæµå®ˆå«

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
```python
class GitGuardian:
    """Gitå®ˆå«"""

    def precommit_check(
        self,
        staged_files: List[Path]
    ) -> PrecommitResult:
        """
        Pre-commité’©å­æ£€æŸ¥

        æ£€æŸ¥é¡¹ï¼š
        1. æ–‡æ¡£æ–‡ä»¶æ˜¯å¦åœ¨å…è®¸çš„ç›®å½•
        2. æ ¹ç›®å½•æ–‡ä»¶æ˜¯å¦åœ¨ç™½åå•
        3. å•æ¬¡PRæ–°å¢æ–‡æ¡£æ•°é‡é™åˆ¶
        4. æ¯ä¸ªæ–‡æ¡£æ˜¯å¦é€šè¿‡validate()
        """
        allowed_files = []
        blocked_files = []

        for file in staged_files:
            # è·³è¿‡éæ–‡æ¡£æ–‡ä»¶
            if not self._is_doc_file(file):
                allowed_files.append(str(file))
                continue

            # æ£€æŸ¥æ ¹ç›®å½•ç™½åå•
            if file.parent == Path("."):
                if file.name not in self.standards.guards.root_allowlist:
                    blocked_files.append(BlockedFile(
                        path=str(file),
                        reason="æ ¹ç›®å½•åªå…è®¸ç‰¹å®šæ–‡ä»¶",
                        fix=self._suggest_doc_location(file)
                    ))
                    continue

            # æ£€æŸ¥æ–‡æ¡£ç›®å½•é™åˆ¶
            if not any(str(file).startswith(d) for d in self.standards.guards.doc_dirs):
                blocked_files.append(BlockedFile(
                    path=str(file),
                    reason="æ–‡æ¡£å¿…é¡»åœ¨docs/ç›®å½•ä¸‹",
                    fix=self._suggest_doc_location(file)
                ))
                continue

            # æ£€æŸ¥æ–‡æ¡£å†…å®¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            doc_type = self._infer_doc_type(file)
            if doc_type and doc_type in self.standards.documents:
                content_meta = self._extract_content_meta(file)
                validation_result = self.validator.validate(doc_type, file, content_meta)

                if not validation_result.ok:
                    blocked_files.append(BlockedFile(
                        path=str(file),
                        reason="æ–‡æ¡£ä¸ç¬¦åˆè§„èŒƒ",
                        violations=validation_result.violations,
                        fix="ä¿®å¤ä¸Šè¿°è¿è§„é¡¹"
                    ))
                    continue

            allowed_files.append(str(file))

        # æ£€æŸ¥æ–°å¢æ–‡æ¡£æ•°é‡é™åˆ¶
        new_docs_count = len([f for f in staged_files if self._is_new_doc(f)])
        if new_docs_count > self.standards.guards.max_new_docs_per_pr:
            return PrecommitResult(
                ok=False,
                action="abort_commit",
                message=f"å•æ¬¡æäº¤æ–°å¢æ–‡æ¡£è¿‡å¤š({new_docs_count} > {self.standards.guards.max_new_docs_per_pr})",
                blocked_files=blocked_files,
                allowed_files=allowed_files
            )

        if blocked_files:
            return PrecommitResult(
                ok=False,
                action="abort_commit",
                message=f"{len(blocked_files)}ä¸ªæ–‡ä»¶è¿åè§„èŒƒï¼Œè¯·ä¿®å¤åé‡æ–°æäº¤",
                blocked_files=blocked_files,
                allowed_files=allowed_files
            )

        return PrecommitResult(
            ok=True,
            action="allow_commit",
            message="æ‰€æœ‰æ–‡ä»¶ç¬¦åˆè§„èŒƒ",
            blocked_files=[],
            allowed_files=allowed_files
        )
```

**Pre-commité’©å­å®‰è£…**ï¼š
```bash
# .git/hooks/pre-commit
#!/bin/bash
set -e

# è·å–stagedæ–‡ä»¶åˆ—è¡¨
STAGED_FILES=$(git diff --cached --name-only)

# è°ƒç”¨MCPæœåŠ¡
RESULT=$(echo "$STAGED_FILES" | project-standards-guard precommit)

# è§£æç»“æœ
if ! echo "$RESULT" | jq -e '.ok' > /dev/null; then
    echo "âŒ Pre-commitæ£€æŸ¥å¤±è´¥:"
    echo "$RESULT" | jq -r '.message'
    echo ""
    echo "é˜»æ­¢çš„æ–‡ä»¶:"
    echo "$RESULT" | jq -r '.blocked_files[] | "  - \(.path): \(.reason)"'
    echo ""
    echo "ä¿®å¤å»ºè®®:"
    echo "$RESULT" | jq -r '.blocked_files[] | "  - \(.fix)"'
    exit 1
fi

echo "âœ… Pre-commitæ£€æŸ¥é€šè¿‡"
exit 0
```

---

### 5. Waiver Manager

**èŒè´£**ï¼šç®¡ç†è§„èŒƒè±å…è¯·æ±‚

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
```python
class WaiverManager:
    """è±å…ç®¡ç†å™¨"""

    def request_waiver(
        self,
        doc_path: Path,
        policy_id: str,
        reason: str,
        requester: str
    ) -> WaiverRequest:
        """
        è¯·æ±‚è±å…

        è®°å½•å†…å®¹ï¼š
        - æ–‡æ¡£è·¯å¾„
        - è±å…çš„ç­–ç•¥ID
        - è±å…åŸå› 
        - è¯·æ±‚è€…
        - æ—¶é—´æˆ³
        """
        waiver = WaiverRequest(
            id=generate_waiver_id(),
            doc_path=str(doc_path),
            policy_id=policy_id,
            reason=reason,
            requester=requester,
            requested_at=datetime.utcnow(),
            status="pending"
        )

        # ä¿å­˜åˆ°å®¡è®¡æ—¥å¿—
        self.audit_logger.log_waiver_request(waiver)

        # å¦‚æœstrict_mode=Falseï¼Œè‡ªåŠ¨æ‰¹å‡†
        if not self.standards.validation.strict_mode:
            waiver.status = "auto_approved"
            waiver.approved_at = datetime.utcnow()

        return waiver

    def is_waived(self, doc_path: Path, policy_id: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²è±å…"""
        waivers = self.audit_logger.get_waivers(doc_path)
        return any(
            w.policy_id == policy_id and w.status in ["approved", "auto_approved"]
            for w in waivers
        )
```

---

## ğŸŒ MCPæœåŠ¡æ¥å£

### APIç«¯ç‚¹å®šä¹‰

#### 1. standards.get
**ç”¨é€”**ï¼šè·å–è§£æåçš„é¡¹ç›®æ ‡å‡†

```python
@mcp_tool
def standards_get(
    project_path: str,
    include_inherited: bool = True
) -> dict:
    """
    è·å–é¡¹ç›®æ ‡å‡†

    Args:
        project_path: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
        include_inherited: æ˜¯å¦åŒ…å«ç»§æ‰¿çš„æ ‡å‡†

    Returns:
        {
            "version": "1.0",
            "source": "merged",
            "documents": {...},
            "guards": {...},
            "validation": {...},
            "inherited_from": ["org-defaults", "repo-local"]
        }
    """
    resolver = StandardsResolver()
    standards = resolver.resolve(Path(project_path))

    return standards.model_dump(
        include_inherited=include_inherited
    )
```

#### 2. doc.suggest_location
**ç”¨é€”**ï¼šæ™ºèƒ½æ¨èæ–‡æ¡£ä½ç½®å’Œç»“æ„

```python
@mcp_tool
def doc_suggest_location(
    doc_type: Literal["epic", "feature", "story", "task", "adr", "sprint"],
    title: str,
    project_context: dict
) -> dict:
    """
    æ¨èæ–‡æ¡£ä½ç½®

    Args:
        doc_type: æ–‡æ¡£ç±»å‹
        title: æ–‡æ¡£æ ‡é¢˜
        project_context: é¡¹ç›®ä¸Šä¸‹æ–‡
            - project_type: "technical_product" | "open_source" | "enterprise"
            - team_size: "small" | "medium" | "large"
            - development_stage: "mvp" | "growth" | "mature"

    Returns:
        {
            "suggested_path": "docs/product/epics/epic-002-...",
            "naming_pattern": "epic-{num}-{kebab}",
            "required_sections": [...],
            "guiding_principles": [...],
            "outline": [...]
        }
    """
    suggester = LocationSuggester(standards)
    context = ProjectContext(**project_context)

    return suggester.suggest(
        doc_type=doc_type,
        title=title,
        project_context=context
    ).model_dump()
```

#### 3. doc.validate
**ç”¨é€”**ï¼šéªŒè¯æ–‡æ¡£æ˜¯å¦ç¬¦åˆè§„èŒƒ

```python
@mcp_tool
def doc_validate(
    path: str,
    content_meta: dict
) -> dict:
    """
    éªŒè¯æ–‡æ¡£

    Args:
        path: æ–‡æ¡£è·¯å¾„
        content_meta: æ–‡æ¡£å…ƒä¿¡æ¯
            - title: str
            - sections: List[str]
            - keywords: List[str]
            - word_count: int

    Returns:
        {
            "ok": false,
            "violations": [
                {
                    "rule": "wrong_location",
                    "severity": "error",
                    "message": "...",
                    "suggested_fix": "..."
                }
            ],
            "principle_scores": {
                "why-over-what": 0.7,
                "tpst-oriented": 0.4
            },
            "overall_score": 0.55,
            "can_proceed": false
        }
    """
    validator = ValidationEngine(standards)
    doc_type = infer_doc_type(Path(path))
    meta = DocumentMeta(**content_meta)

    return validator.validate(
        doc_type=doc_type,
        path=Path(path),
        content_meta=meta
    ).model_dump()
```

#### 4. git.guard.precommit
**ç”¨é€”**ï¼šPre-commité’©å­æ£€æŸ¥

```python
@mcp_tool
def git_guard_precommit(
    staged_files: List[str]
) -> dict:
    """
    Pre-commitå®ˆå«

    Args:
        staged_files: Git stagedæ–‡ä»¶åˆ—è¡¨

    Returns:
        {
            "ok": false,
            "action": "abort_commit",
            "message": "1ä¸ªæ–‡ä»¶è¿åè§„èŒƒ",
            "blocked_files": [
                {
                    "path": "docs/temp.md",
                    "reason": "è¿åå‘½åè§„èŒƒ",
                    "fix": "é‡å‘½åä¸º docs/knowledge/..."
                }
            ],
            "allowed_files": [...]
        }
    """
    guardian = GitGuardian(standards)

    return guardian.precommit_check(
        staged_files=[Path(f) for f in staged_files]
    ).model_dump()
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### ç¼“å­˜ç­–ç•¥

```python
class StandardsCache:
    """æ ‡å‡†ç¼“å­˜"""

    def __init__(self):
        self.cache = {}
        self.ttl = 3600  # 1å°æ—¶

    @lru_cache(maxsize=128)
    def get_resolved_standards(self, project_path: str) -> ResolvedStandards:
        """ç¼“å­˜è§£æåçš„æ ‡å‡†"""
        cache_key = self._generate_cache_key(project_path)

        if cache_key in self.cache:
            cached_item = self.cache[cache_key]
            if time.time() - cached_item.timestamp < self.ttl:
                return cached_item.standards

        # è§£ææ ‡å‡†
        resolver = StandardsResolver()
        standards = resolver.resolve(Path(project_path))

        # æ›´æ–°ç¼“å­˜
        self.cache[cache_key] = CacheItem(
            standards=standards,
            timestamp=time.time()
        )

        return standards
```

### å¼‚æ­¥éªŒè¯

```python
class AsyncValidator:
    """å¼‚æ­¥éªŒè¯å™¨"""

    async def validate_async(
        self,
        doc_type: str,
        path: Path,
        content_meta: DocumentMeta
    ) -> ValidationResult:
        """å¼‚æ­¥éªŒè¯ï¼Œä¸é˜»å¡ä¸»æµç¨‹"""

        # å¿«é€ŸéªŒè¯ï¼ˆåŒæ­¥ï¼‰
        quick_checks = self._quick_validate(doc_type, path, content_meta)
        if not quick_checks.ok:
            return quick_checks

        # åŸåˆ™è¯„åˆ†ï¼ˆå¼‚æ­¥ï¼‰
        principle_scores = await self._score_principles_async(
            doc_type, content_meta
        )

        return ValidationResult(
            ok=True,
            violations=[],
            principle_scores=principle_scores,
            overall_score=sum(principle_scores.values()) / len(principle_scores)
        )
```

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•

```python
# test_standards_resolver.py
def test_resolve_with_inheritance():
    """æµ‹è¯•æ ‡å‡†ç»§æ‰¿å’Œåˆå¹¶"""
    # Given: ç»„ç»‡çº§+é¡¹ç›®çº§æ ‡å‡†
    org_standards = load_standards("org_defaults.yml")
    project_standards = load_standards(".project_standards.yml")

    # When: è§£æåˆå¹¶
    resolver = StandardsResolver()
    resolved = resolver.merge_standards(org_standards, project_standards)

    # Then: é¡¹ç›®çº§è¦†ç›–ç»„ç»‡çº§
    assert resolved.documents["epic"].location == project_standards.documents["epic"].location
    assert "org-principle" in [p.id for p in resolved.documents["epic"].principles]
    assert "project-principle" in [p.id for p in resolved.documents["epic"].principles]

# test_validation_engine.py
def test_validate_missing_section():
    """æµ‹è¯•ç¼ºå¤±å¿…å¡«ç« èŠ‚æ£€æµ‹"""
    # Given: Epicç¼ºå°‘"ä¸šåŠ¡ä»·å€¼"ç« èŠ‚
    content_meta = DocumentMeta(
        title="Test Epic",
        sections=["æ¦‚è¿°", "Features"],
        keywords=[]
    )

    # When: éªŒè¯
    validator = ValidationEngine(standards)
    result = validator.validate("epic", Path("docs/product/epics/epic-001/"), content_meta)

    # Then: åº”è¯¥æŠ¥é”™
    assert not result.ok
    assert any("missing_section:ä¸šåŠ¡ä»·å€¼" in v.rule for v in result.violations)
```

### é›†æˆæµ‹è¯•

```python
# test_mcp_integration.py
def test_full_workflow():
    """æµ‹è¯•å®Œæ•´çš„å»ºè®®â†’éªŒè¯â†’å®ˆå«æµç¨‹"""
    # 1. å»ºè®®ä½ç½®
    suggestion = doc_suggest_location(
        doc_type="epic",
        title="Tool Intelligence",
        project_context={
            "project_type": "technical_product",
            "team_size": "small"
        }
    )

    assert "docs/product/epics/" in suggestion["suggested_path"]

    # 2. åˆ›å»ºæ–‡æ¡£ï¼ˆæ¨¡æ‹Ÿï¼‰
    doc_path = suggestion["suggested_path"] + "README.md"

    # 3. éªŒè¯æ–‡æ¡£
    validation = doc_validate(
        path=doc_path,
        content_meta={
            "title": "Tool Intelligence",
            "sections": ["ä¸šåŠ¡ä»·å€¼", "æˆåŠŸæŒ‡æ ‡", "Features"],
            "keywords": ["TPST", "tokens"],
            "word_count": 500
        }
    )

    assert validation["ok"]
    assert validation["principle_scores"]["tpst-oriented"] >= 0.6

    # 4. Pre-commitå®ˆå«
    guard_result = git_guard_precommit(staged_files=[doc_path])

    assert guard_result["ok"]
    assert doc_path in guard_result["allowed_files"]
```

### TPSTåŸºå‡†æµ‹è¯•

```python
# test_tpst_benchmark.py
def test_tpst_comparison():
    """å¯¹æ¯”æœ‰/æ— çº¦æŸçš„TPST"""
    # Baseline: æ— çº¦æŸåˆ›å»ºæ–‡æ¡£
    baseline_tokens = simulate_doc_creation_without_standards(
        task="åˆ›å»ºEpicå…³äºå·¥å…·æ™ºèƒ½"
    )
    # é¢„æœŸ: ~1200 tokensï¼ˆå¤šæ¬¡è¿”å·¥ï¼‰

    # Optimized: æœ‰çº¦æŸåˆ›å»ºæ–‡æ¡£
    optimized_tokens = simulate_doc_creation_with_standards(
        task="åˆ›å»ºEpicå…³äºå·¥å…·æ™ºèƒ½"
    )
    # é¢„æœŸ: ~750 tokensï¼ˆé¦–æ¬¡æˆåŠŸï¼‰

    reduction_percentage = (baseline_tokens - optimized_tokens) / baseline_tokens

    assert reduction_percentage >= 0.30, f"TPSTé™ä½ä¸è¶³30%: {reduction_percentage:.1%}"

    print(f"âœ… TPSTé™ä½: {reduction_percentage:.1%}")
    print(f"   Baseline: {baseline_tokens} tokens")
    print(f"   Optimized: {optimized_tokens} tokens")
```

---

## ğŸš€ éƒ¨ç½²æ–¹æ¡ˆ

### ç‹¬ç«‹MCPæœåŠ¡éƒ¨ç½²

```bash
# 1. å®‰è£…
pip install project-standards-mcp

# 2. é…ç½®
cat > ~/.config/project-standards/config.yml <<EOF
service:
  host: localhost
  port: 8080

cache:
  enabled: true
  ttl_seconds: 3600

logging:
  level: INFO
  file: ~/.config/project-standards/logs/service.log
EOF

# 3. å¯åŠ¨æœåŠ¡
project-standards-mcp serve

# 4. é…ç½®Claude Codeä½¿ç”¨æ­¤MCP
cat >> ~/.config/claude-code/mcp_servers.json <<EOF
{
  "project-standards": {
    "url": "http://localhost:8080",
    "enabled": true
  }
}
EOF
```

### é¡¹ç›®åˆå§‹åŒ–

```bash
# é¡¹ç›®ä¸­åˆå§‹åŒ–æ ‡å‡†
cd /path/to/project
project-standards init

# é€‰æ‹©æ¨¡æ¿
? é€‰æ‹©é¡¹ç›®ç±»å‹:
  â¯ Technical Product
    Open Source
    Enterprise Application
    Research Project

? å›¢é˜Ÿè§„æ¨¡:
  â¯ Small (1-5äºº)
    Medium (6-20äºº)
    Large (>20äºº)

# ç”Ÿæˆ .project_standards.yml
âœ… å·²ç”Ÿæˆ .project_standards.yml
âœ… å·²å®‰è£… pre-commit é’©å­
âœ… å·²æ·»åŠ åˆ° .gitignore
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### ç›¸å…³æ–‡æ¡£
- [Epic-002: é¡¹ç›®è§„èŒƒå³æœåŠ¡](../../product/epics/epic-002-project-standards/README.md)
- [Epic-001: è¡Œä¸ºçº¦æŸç³»ç»Ÿ](../../product/epics/epic-001-behavior-constraints/README.md)
- [ExecutionPlan Schema](../../product/epics/epic-001-behavior-constraints/story-001-execution-plan-schema.md)

### å¤–éƒ¨èµ„æº
- [MCP Protocol Specification](https://spec.modelcontextprotocol.io/)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [Git Hooks Documentation](https://git-scm.com/docs/githooks)

---

**æœ€åæ›´æ–°**: 2025-10-27
**æ›´æ–°äºº**: EvolvAI Team
